# 操作系统

# 1.操作系统引论

## 1.1操作系统的目的和作用

### 1.1.1操作系统的目标

通常在计算机硬件配置的OS(操作系统),其目标有以下几点:

1. 方便性——便于使用
2. 有效性——效率高
3. 可扩充性——方便增加模块
4. 开放性——兼容性

### 1.1.2操作系统的作用

1. OS作为用户与计算机硬件系统之间的接口

   OS处于用户与计算机硬件系统之间，用户通过OS来使用计算机系统

## 1.2操作系统的发展过程

### 1.2.1无操作系统的计算机系统

1. 穿孔

2. 纸带

3. 卡片

4. 纸带输入机

5. 卡片输入机

   缺点：

   1. 用户独占全机
   2. CPU等待人工操作

### 1.2.2单道批处理系统

### 1.2.3多道批处理系统

### 1.2.4分时系统

1. 分时系统的产生

   推动分时系统产生和发展的主要动力，则是用户的需求：<u>**人机交互，共享主机**</u>

2. 分时系统实现中的关键问题

   **<u>最关键的问题是如何使用户能与自己的作业进行交互</u>**

   1. 及时接收
   2. 及时处理

3. 分时系统的特征

   1. **<u>多路性</u>**
   2. **<u>独立性</u>**
   3. **<u>及时性</u>**
   4. **<u>交互性</u>**

### 1.2.5实时系统

**实时系统**是指系统能及时（或即时）响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地运行

<u>**应用需求 1、实时控制 2、实时信息处理**</u>

**<u>硬实时任务：工业控制系统，嵌入式系统</u>**

**<u>软实时任务：信息查询系统，多媒体系统</u>**

1. 分时系统侧重于：多个用户终端的互不干扰，人机交互。
2. 实时系统侧重于：多路控制现场设备、数据互不干扰，特定程序间的数据信息交互。

## 1.3操作系统的基本特性

*并发性*：**宏观同时，微观交错**

*共享性*：**并发执行，共用资源**

*虚拟性*：**物理设备**<u>**(单个)**</u> 	**<u>复用</u>**	—>	**逻辑设备**<u>**(多个)**</u> 	**<u>时分复用	空分复用</u>**

*异步性*：**多进程交替，执行断续性**

注意：*并行与并发的区别*

**<u>并发</u>和<u>共享</u>是操作系统的两个最基本的特征，它们互为存在的条件。**

## 1.4操作系统的主要功能

操作系统是一组控制和管理计算机硬件和软件资源、合理地对各类作业进行调度，以及方便用户的程序的集合

## 1.5操作系统的结构设计

### 1.5.1传统的操作系统结构

四代变革：

1. 传统结构操作系统
   1. 无结构OS
   2. 模块式OS
   3. 层次式结构OS
2. 现代结构操作系统
   1. 客户/服务器模式
   2. 面向对象的程序设计
   3. 微内核结构OS

# 2.进程管理

## 2.1进程的基本概念

### 2.1.1前趋图

广度搜索

### 2.1.2程序并发执行时的特征：

1. 间断性
2. 失去封闭性
3. 不可再现性

### 2.1.3程序顺序执行时的特征：

1. 顺序性
2. 封闭性
3. 可再现性

## 2.2进程控制

### 2.2.1进程的定义和特征

1. **<u>进程的定义</u>**：

   1. 进程是程序的一次<u>**执行**</u>，是进程实体的**<u>运行过程</u>**
   2. 进程是可并发执行的<u>**程序**</u>在一个<u>**数据集合**</u>上的运行过程。它是系统进行资源分配和调度的一个独立单位.

   进程实体由程序段、数据段、进程控制块(<u>**PCB**</u>)构成

   注：进程与程序的主要区别

   <u>程序</u>是指令的集合，本身没有任何运行的含义，是一个静态概念；而<u>**进程**</u>是程序在处理机上的一次执行过程，是一个动态概念。

### 2.2.2进程基本状态及其转换

**进程的状态反映进程执行过程的变化**

1. **进程的三种基本状态**：

   **运行态**：**进程占有CPU，并在CPU上运行**

   **就绪态**：指进程已获得了除处理机之外的所有所需的资源，已经具备运行条件，但由于无CPU暂时不能运行的状态。（当调度给其CPU时，立即可以运行）

   **阻塞态**：**等待态、封锁态、睡眠态**。指进程因等待某种事件的发生而暂时不能运行的状态（即使CPU空闲，该进程也不可能运行）

2. 三种基本状态的转换

   进程因某事件从运行到阻塞状态

   某事件被解除从阻塞变成就绪

   时间片用完从运行到就绪

   进程调度程序把处理机分配给进程从就绪到运行

### 2.2.4进程管理中的数据结构PCB

**PCB是操作系统中最重要的数据结构，是进程存在的唯一标志；是独立运行的基本单位，是资源分配的基本单位。**

进程控制块的信息和作用：

​	<u>**进程标识信息**</u>，是进程的唯一标识

​	<u>**处理机状态**</u>，即是现场信息保存的地方，从而能实现间断性运行方式：
​	<u>**进程调度信息**</u>：提供进程调度所需要的信息；
​	<u>**进程控制信息**</u>：提供进程管理所需要的信息，所有资源的列表；实现与其他进程的同步与通信

PCB的组织方式

1. 链接方式
2. 索引方式

## 2.3进程同步

### 2.3.1操作系统内核

为了确保系统的安全性，常将处理机的执行状态分为<u>**系统态**</u>和<u>**用户态**</u>。

进程控制由操作系统内核实现，运行于系统态。

<u>**OS内核**</u>是计算机硬件的第一次扩充，由一些与硬件紧密相关的模块和运行频率较高的模块构成，例如中断，各种管理，进程调度的，驱动程序等等。内核常驻内存，受特殊保护，为了效率高和安全性。

**<u>原语</u>**是由若干条指令组成的，用于完成特定功能的一个特殊过程。它与一般过程的区别在于：它们是**<u>原子操作</u>**，不能被打断。

### 2.3.2进程的创建

1. 申请空白PCB
2. 为新进程分配资源
3. 初始化进程控制块
   1. 初始化表示信息
   2. 初始化处理机状态信息，pc指针等现场信息
   3. 初始化处理机控制信息：状态，优先级
4. 将新进程插入就绪队列，如果进程就绪队列能够接纳新进程， 便将新进程插入就绪队列

## 2.4经典进程的同步问题

<u>**进程同步**</u>： 指对多个相关进程在执行次序上的协调。

<u>**进程同步的主要任务**</u>：  使并发执行的诸进程间能有效地共享资源和相互合作，从而使程序的执行具有可再现性。

### 2.4.1进程同步的基本概念

1. 两种形式的制约关系：

   1. *资源共享关系（间接互相制约）*<u>**互斥解决**</u>
   2. 相互合作关系（直接相互制约）<u>**同步解决**</u>

2. 临界资源

   一段时间内只允许一个进程访问的资源；临界资源要求互斥的被访问。

3. 临界区的定义

   各进程中访问临界资源的程序代码称为临界区。

4. 同步机制遵循的规则

   1. 空闲让进
   2. 忙则等待
   3. 有限等待
   4. 让权等待

### 2.4.2硬件同步机制

硬件的理解，解决方式：

1. 关中断：

   缺点：

   1. 滥用关中断，会有严重后果
   2. 关中断时间过长，效率会低
   3. 不适用多cpu系统

   方法2/3都相当于加锁方式原理：

   1. 如果锁lock=true，就while循环等待
   2. 一旦false了，就马上出循环，lock=true，并使用资源；
   3. 使用完资源了，lock=false

### 2.4.3信号量机制

通过两个标准的原子操作：<u>**wait(S)**</u>和<u>**signal(S)**</u>来访问。这两个操作一般被分别称为<u>**P、V操作**</u>。

1. 整形信号量

   ```c++
   wait(S){  while （S≤0）;
             S=S-1;   }
   ```

   P操作：实现资源分配

   ```c++
   signal(S){S=S+1;}
   ```

   V操作：实现资源回收

2. 记录型信号量

   整型变量value：代表资源数目

   进程链表指针L：链接等待该资源的进程

   ```c++
   typedef struct {
          int  value;
           Block_List  * list;      
            } semaphore
   wait(semaphore  *S)
   {
         S->value--;
         if (S->value＜0 )
              block(S->list)
   }
   signal(semaphore  *S)
         S->value++;
         if (S->value＜=0 )
              wakeup(S->list)
   }
   ```

   1. <u>**S.value的初值表示系统中某类资源的数目**</u>， 因而又称为资源信号量，每次wait操作意味着进程请求一个单位的该类资源，S.value:=S.value-1 
   2. 当S.value＜0时，进程自阻塞，<u>**S.value的绝对值表示在该信号量链表中已阻塞进程的数目**</u>。
   3. 该机制遵循了“让权等待”准则。
   4. 如果<u>**S.value的初值为1**</u>，表示只允许一个进程访问临界资源，此时的信号量<u>**转化为互斥信号量**</u>。 

## 2.5进程通信

进程通信是指进程之间的信息交换。根据信息量的大小，可把进程之间的通信分成<u>**低级通信**</u>和<u>**高级通信**</u>。

### 2.5.1进程通信的类型

1. 共享存储器系统：

   1. 基于共享数据结构的通信方式：信号量
   2. 基于共享存储区的通信方式

2. 管道通信：

   利用一个打开的pipe共享文件连接两个相互通信的进程。有效的传送大量的数据。

3. 消息传递系统：

   1. 直接通信方式：消息传递原语
   2. 间接通信方式：邮箱通信

## 2.6线程

### 2.6.1线程的引入

进程的创建和切换开销比较大，为了减少进程切换和创建的开销，提高执行效率和节省资源，以及为了方便进程间共享数据和交换数据，引入“线程”。

### 2.6.2线程的实现

两种：

1. 内核级线程
   1. CPU是内核直接分配给线程的
2. 用户级线程
   1. CPU的是分配给进程的，进程自己的分配给线程

特点：

1. 内核不了解用户线程的存在；
2. 用户线程切换不需要内核特权
3. 调度由应用软件内部进行，通常采用非抢先式和更简单的规则，也无需用户态/核心态切换，所以速度特别快。

# 3.处理机调度与死锁

## 3.1处理机调度的层次

### 3.1.1处理机调度的层次

<u>**高级调度**</u>：选取输入井中的作业（仅限于批作业调度)，生成根进程，开始执行作业步.目的是控制使用系统资源的进程数。

<u>**中级调度**</u>：选取进程占用内存或有资格占用内存，又称进程滚入滚出。

<u>**低级调度**</u>：选取进程占用处理机,又称进程调度。

<u>进程调度</u>：是指按一定的调度算法从就绪队列中选中一个进程，把CPU的使用权交给被选中的进程，从而控制协调进程对CPU的竞争。

### 3.1.2调度算法的目标

**性能衡量的指标**：

​	**周转时间**：一个作业从提交到返回所需的时间。

​	**<u>平均周转时间</u>**：
$$
T = \frac 1 n [ \sum_ {i=1} ^n T_i ]
$$
**面向用户的准则**：周转时间短；响应时间快；截止时间的保证；优先权准则

**面向系统的准则**：系统吞吐量高；处理机利用率好；各类资源的平衡利用。

## 3.2作业与作业调度

### 3.2.3作业调度算法:

1. 先进先出（FIFO）算法
2. 最短CPU运行期优先调度算法
3. 最高响应比优先法
4. 优先级法

**最高响应比优先法** 
是前两种算法的综合平衡，既要考虑到服务时间也要考虑到等待时间，响应比作为优先权：
$$
优先权=\frac{等待时间+要求服务}{要求服务时间}=\frac{响应时间}{要求服务时间}
$$


## 3.3调度算法

### 3.3.2基于时间片的轮转调度算法

1. 时间片轮转法

   1. 基本原理：把CPU按时间片分配给进程，<u>**进程按时间片大小轮流执行**</u>。
   2. 进程切换时机
   3. 时间片的大小选择，从几ms到几百ms

2. 多队列反馈调度算法

   1. 就绪队列分为N级，每个就绪队列分配给不同的时间片
   2. 队列级别越低，时间越长，级别越高，时间片越小
   3. 最后一级采用时间片轮转，其他队列采用先进先出

   调度处理：

   1. 系统从第一级调度，第一级为空时，系统转向第二个队列...
   2. 当进程第一次就绪时，进入第一级队列
   3. 当运行进程用完一个时间片，放弃CPU时，进入下一级队列
   4. 因为等待事件放弃CPU时，进入原来的(或更高的)就绪队列

## ~~3.4实时调度~~

## 3.5产生死锁的原因和必要条件

死锁（Deadlock）定义：是指系统中多个进程无休止地等待永远不会发生的条件，若无外力作用，这些进程都将无法向前推进。

产生死锁的原因是：系统资源不足；并发进程执行时推进顺序不当。

产生死锁几个必要条件

1. 互斥条件
2. 请求和保持条件（部分分配条件）
3. 不可抢占条件
4. 循环等待条件

**解决死锁的基本方法**

1. <u>**死锁预防**</u>：事先就破坏其中一个必要条件
2. <u>**死锁避免**</u>：分配资源的时候，检测是不是安全，如果不安全就不分配。
3. <u>**死锁检测、解除死锁（死锁的检测和恢复）**</u>：事先不管，定时检测是否有死锁，有则解除死锁。

## 3.6预防死锁的方法

1. 破坏必要条件中的部分分配条件，对进程申请的资源一次性全部分配
2. 破坏必要条件中的不可抢占条件，进程申请新资源的请求不能满足时，必须释放已占有的资源
3. 破坏必要条件中的循环等待条件，按一定的资源序列号升序地分配资源

## 3.7死锁的避免

**实质：在资源的动态分配过程中**，使系统不进入<u>**不安全状态**</u>。 在避免死锁的方法中，允许进程动态地申请资源，但系统在<u>**进行资源分配之前**</u>，应先计算此次资源分配的<u>**安全性**</u>。若此次分配不会导致系统进入不安全状态，则将资源分配给进程； 否则，令进程等待。

避免死锁算法最有代表性的是Dijkstra提出的<u>**银行家算法**</u>。

​	思想：

1. 假设，分配给你资源后（值修改）；

2. 判断是否为安全状态，是则分配，不是则不分配。

   **怎样判断是不是安全状态（安全算法）：看能不能找到一个安全序列**

### 系统的安全状态

系统状态：

​	<u>**安全状态**</u>：指系统能按照某种顺序如
$$
<P1,P2,…,Pn>
$$
 (称为这个序列为安全序列)，为每个进程分配所需的资源，直至最大需求，使得每个进程都能顺利完成。

​	<u>**非安全状态**</u>：即在某个时刻系统中不存在一个安全序列，则称系统处于不安全状态或非安全状态。

**<u>因此，避免死锁的实质是如何使系统不进入不安全状态</u>**

## 3.8死锁的检测与解除

### 3.8.1死锁的检测：判定系统是否发生了死锁

# 4.存储器管理

**主要任务**：

1. 为多道程序的运行提供良好的环境（安全可靠）
2. 提高存储器的利用率
3. 逻辑上扩充内存

**主要功能：**

1. 内存分配
2. 地执映射
3. 内存保护
4. 内存扩充

## 4.1存储器的层次结构

### 4.1.1多级存储器结构

1. 寄存器
2. 高速缓存
3. 主存
4. 磁盘缓存
5. 磁盘
6. 磁带、光盘、移动存储等

速度由快到慢，容量从小到大，价格从高到低

## 4.2程序的装入和链接 

程序	**编译**	到目标模块	**链接**	到装入模块	**装入**	内存

### 地址转换—基本概念：

**逻辑地址（相对地址，虚地址）** ：用户的程序经过汇编或编译后形成目标代码，目标代码通常采用相对地址的形

式，其首地址为0，其余指令中的地址都相对于首地址而编址。**由编译程序生成，不能用逻辑地址在内存中读取信息**。

**物理地址（绝对地址，实地址）**：内存中存储单元的地址，可直接寻址。

**地址转换**：为了保证CPU执行指令时可正确访问存储单元，需将用户程序中的逻辑地址转换为运行时由机器直接寻址的物理地址，这一过程称为地址映射。

### 地址映射

**静态地址转换**
当用户程序被装入内存时，一次性实现逻辑地址到物理地址的转换，以后不再转换一般在装入内存时由软件完成

**动态地址转换**
在程序运行过程中要访问数据时再进行地址变换(一般此工作由硬件地址映射机制来完成)硬件上需要寄存器的支持

### 4.2.1程序的装入

1. 绝对装入方式：

   <u>**适用于单道环境，例如单片机**</u>

2. 可<u>**重定位**</u>装入方式

   <u>**静态地址映射**</u>

3. 动态运行时装入方式

   <u>**动态地址映射**</u>

### 4.2.2程序的链接

程序链接：将几个目标模块装配成一个装入模块

1. **静态链接方式**

2. **装入时动态链接**

   装入时动态链接的<u>**优点**</u>：

   1. **<u>便于修改和更新</u>**
   2. **<u>便于实现对目标模块的共享</u>**

   缺点：所有的模块都装入了

3. **运行时动态链接**

   许多情况下，程序在运行时，每次要运行的模块可能是不相同的 ，**目前流行的是动态链接，是运行时再把需**
   **要的模块装入进去**。

## 4.3连续分配方式 

连续空间分配：进程的空间是连续的。

### 4.3.1单一连续分配：

1. 只能用于单用户、单任务操作系统

2. 内存分为系统区和用户区两部分

   **特点：易理解、效率高、空间利用率低**

### 4.3.2固定分区分配：

特点：任一时刻内存可有多道内存，每个内存连续存放于内存.

**基本思想**：

**系统把内存用户区划分为若干块，每块称为分区。**

**分区大小可相同也可不同。**

**一个进程占据一个分区。**

**分区大小固定不变的称为固定分区**

### 4.3.3-4.3.4动态分区分配和分配算法

**特点：多道、连续、但不固定划分内存**

1. 管理方法：

   系统设置一个空闲块队列，初始状态时队列中只有一个连续的空闲块。作业到达后，以某种策略分配空间。作业撤离时，将释放的空间加入空闲队列

**分配方法**：

按照一定的分配策略，找到合适的空闲块后，从其中将作业大小的空间分给作业，而剩余部分挂入空闲队列。

分配策略包括：

**首次适应法**：从F(可用块集合)中最先找到的空闲块

**循环首次适应算法**：从上次的位置的下一个位置开始找，而不是又从头找

**最佳适应法**：从F中找到的满足条件的最小空闲块。

**最大满足法**:从F中找到的满足条件的最大空闲块。

### 4.3.6动态可重定位分区分配

1. **紧凑：通过移动作业位置可以将零散的空闲块连接成大块。要求作业动态可浮动。**

## 4.4对换

1. 对换的引入：**解决内存扩充问题**

   **<u>对换</u>**：把内存中暂时不能运行的进程或者暂时不用的程序和数据，调出到外存上。

   **<u>对换是提高内存利用率的有效措施</u>**

   1. 整体对换—>进程对换
   2. 部分对换（页面对换，分段对换）

## 4.5分页存储管理方式

<u>**离散分区分配**</u>：将一个进程（或作业）直接分散地分配到许多不必相邻接的分区中，而不需要进行“紧凑”

离散分区分配方式，包括：

1. 分页存储管理
2. 分段存储管理
3. 段页式存储管理

### 4.5.1分页存储管理的基本方法

1.**基本思想（工作原理）	空间安排**：

进程分成页面，内存也划分成页面，以**页为单位**进行分配，并按**进程的页数**多少来分配，将进程页面不连续地分

布到内存页面

2.**地址结构**

页号P	位移量W
$$
P=INT[\frac AL]
$$

$$
W = [A] MOD L
$$
3.页表

**页表：存放逻辑页与物理页帧的对应关系**。

### 4.5.2地址变换结构

$$
分页逻辑地址=P(页号)·W(页内位移)
$$

$$
分页物理地址=f(页帧号)·W(页内位移)
$$

**给一个逻辑地址、页面大小和页表，会计算该逻辑地址对应的物理地址。**

怎么计算：

1.计算逻辑页号和页内偏移

2.查找页表，找出对应的物理块号

3.计算出物理地址：物理块号*页面大小+页内偏移

### 4.5.3两级和多级页表

页表的问题：

1. 逻辑地址空间越来越大(2^32^~2^64^)
2. 页表也就变得非常大，占用内存空间越来越大

## 4.6分段存储管理方式 

**段式管理的空间划分**：按作业的自然段将其逻辑空间分成若干段，作业以段为单位分配内存。

### 4.6.2分段系统的基本原理

1. 分段

   分段管理中的地址结构：

   段号（31-16）+段内地址（15-0）

2. 段表

### 4.6.3信息共享

可重用代码（纯代码）

**段页式管理**：结合段式和页式两种方法，将作业分成若干段，每段用页式管理实现内存分配。

# 5.虚拟存储器

## 5.1虚拟存储器概述

1. 常规存储器管理方式的特征

   1. 装入的一次性
   2. 作业的驻留性

2. 局部性原理

   ​	**<u>局部性规律</u>**：**在以较短时间内，程序的执行仅限于某个部分；相应地，他所访问的存储空间也局限于某个区域。**

3. 主要表现

   时间局限性：程序指令是最近它执行了，不就有可能再被执行，数据也一样。

   空间局限性：程序在一段时间内所访问的地址可能集中在一定的范围内。

4. 虚拟存储器基本工作情况

   1. 静态页式管理：运行之前把所有全部装入内存
   2. 动态页式管理：开始只装入一个或几个，其他的等需要时，再装入。

## 5.2请求分页存储管理方式

### 5.2.1请求分页中的硬件支持

1. 页表机制

   页号|物理块号|状态位存在位P|访问字段A被访问的信息|修改位M|外存地址

2. 缺页中断机构

### 5.2.3调页策略

​	**缺页率**

​	假设一个进程的逻辑空间为n页；系统为其分配的页面个数为m页；访问页面成功的次数为S次；访问页面失败的次数为F次；
$$
缺页率 f=(\frac FS+F)
$$
影响缺页率的因素：

页面大小、m、置换算法、程序的特性

## 5.3页面置换算法

### 5.3.1最佳置换算法和先进先出置换算法

1. 最佳(Optimal)置换算法
2. 先进先出(FIFO)页面置换算法
3. 最近最久未使用(LRU)置换算法

### 5.3.3Clock置换算法

1. 简单的Clock置换算法

   分值判断方法

2. 改进型Clock置换算法

   使用指针和表置换

# 6.输入输出系统

I/O系统是操作系统中最繁琐且与硬件最紧密相关的部分

## 6.1I/O系统的功能、模型和接口

I/O系统管理的主要**对象**是I/O设备和相应的设备控制器

I/O系统管理的主要**任务**：

​	完成用户提出的I/O请求

​	提高I/O速率

​	提高I/O设备的利用率

​	为用户提供一个友好的透明接口

### 6.1.2I/O系统的层次结构和模型

用户进程—>用户层I/O（提供系统调用函数，产生I/O请求）—>设备独立软件（设备无关的I/O，映射）—>设备驱动程序（转换具体命令和参数）中断处理程序（直接与硬件交互）—>硬件

### 6.1.3I/O系统接口

**<u>块设备</u>**接口：将对文件的操作转设备能识别的较底层具体操作，隐藏磁盘的二维机构。

**<u>流设备接口</u>**：是<u>**字符设备**</u>与高层的接口，包括open 、close， get  put等操作

**<u>网络通信设备</u>**：socket套接字接口，把ip数据包转换成数据帧，让设备发送出去

## 6.2I/O设备和设备控制器

### 设备和CPU之间的接口

I／O设备一般由机械和电子两部分组成

1. 物理设备：机械部分是设备本身

2. 设备控制器：操作系统只与控制器打交道

   电子部分叫做设备控制器或适配器

   完成设备与主机间的连接和通信

   通过若干**<u>接口寄存器</u>**或**<u>接口缓冲区</u>**与CPU通信

### 6.2.3内存映像I/O（端口寄存器编址）

内存映像编址（内存映像I/O模式）

I/O独立编址（I/O专用指令）

## 6.3中断机构和中断处理程序

## 6.4设备驱动程序

### 6.4.2设备驱动程序的处理过程

主要任务：**启动指定设备，完成上层指定定的I/O工作，向控制器中的命令寄存器传送相应的控制命令**。

I/O控制方式：怎样和设备通信

控制设备与主机（内存或CPU）之间的数据传送：

1. 直接I/O（轮询）
2. 中断驱动I/O
3. DMA
4. 通道

### DMA方式

前两种方式的缺陷：

1. CPU为管理I/O耗费大量时间。
2. 传输需要CPU寄存器转发。

DMA（直接内存存取）负责完成整个I/O操作，无需再经CPU寄存器转发，并在全部传输结束后向CPU发中断信号

数据在内存与I/O设备间的直接成块传送

**DMA方式与中断的主要区别**

DMA方式则是在所要求传送的数据块全部传送结束时要求CPU进行中断处理

​    **大大减少了CPU进行中断处理的次数**

中断方式的**数据传送**是**由CPU控制完成**的而DMA方式则是在**DMA控制器**的控制下不经过CPU控制完成的

## 6.5与设备无关的I/O软件

### 6.5.3设备分配

**分配用数据结构**

设备的分配和管理，通过下列数据机构进行：

1. 设备控制表DCT（设备控制块DCB）
2. 系统设备表SDT
3. 控制器控制表COCT（控制器控制块）
4. 通道控制表CHCT（通道控制块CHCB）

### 分配过程

1. 根据用户请求的I/O设备的逻辑名，查找逻辑设备和物理设备的**映射表**
2. 以物理设备为索引，查找**SDT**，找到该设备所连接的**DCT**
3. 继续查找与该设备链接的**COCT**和**CHCT**，就找到了一条通路

## 6.6用户层的I/O软件

### 6.6.2SPOOLing技术（假脱机技术）

1. 什么是SPOOLing
   1. 缓和CPU的高速性与I/O设备低速性间的矛盾
   2. **利用两个程序**来模**拟脱机输入/输出**时的外围控制机功能
   3. 此时的外围操作与CPU对数据的处理同时进行

SPOOLing假脱机操作：**<u>用两道进程来模拟脱机输入输出时的外围控制机功能</u>**，把低速I/O设备上的数据传送到高速磁盘上；再用另一道程序来模拟脱机输出时外围控制机的功能，把数据从磁盘传送到低速输出设备上。

## 6.7缓冲区管理

### 6.7.1缓冲的引入

1. 缓和CPU与I/O设备间速度不匹配的矛盾
2. 减少对CPU的中断频率，放宽对CPU中断影响时间的限制
3. 提高CPU和I/O设备之间的并行性

**实现方法有哪些：**

6.7.2单缓冲和双缓冲

6.7.3循环缓冲

6.7.4缓冲池

## 6.8磁盘存储器的性能和调度

**磁盘访问时间**

1. 寻道时间Ts:这是指把磁臂（磁头）移动到指定磁道上所经历的时间。
   $$
   T_s = M*N+S
   $$

2. 旋转延迟时间Tτ：这是指定扇区移动到磁头下面所经历的时间。

3. 传输时间Tt：这是指把数据从磁盘读出或向磁盘写入数据所经历的时间。
   $$
   T_t = T_s +(\frac1 {2r}+\frac b{rN})
   $$
   

### 6.8.2磁盘调度

1. 先来先服务FCFS
2. 最短寻到时间优先SSTF
3. SCAN算法--电梯梯度算法
4. 循环扫描（CSCAN）算法
5. N-Step-SCAN和FSCAN调度算法

# 7.文件管理

## 7.1文件和文件系统

### 7.1.1文件、记录和数据项

1. **数据项**：用于描述一个对象的某种属性的字符集。
2. **记录**：一组描述一个对象某方面属性的相关数据项的集合。
3. **文件**：是由创建者所定义的，具有符号名的一组相关联元素的有序序列，**可分为有结构文件和无结构文件**。
4. **文件系统**：指负责存取和管理辅助存储器上文件信息的机构。

### 7.1.2文件类型和文件系统模型

1. 文件名和扩展名
   1. 文件名
   2. 扩展名 用于指示文件的类型
2. 文件类型
   1. .doc
   2. .txt

### 7.1.3文件系统的层次结构

1. **对象及其属性：文件管理系统管理的对象有：**文件、目录、磁盘（磁带）存储空间
2. **对对象操作和管理的软件集合，这是文件管理系统的核心部分。文件系统的功能**大多是在这一层实现的，包括：存储空间的管理、目录的管理、物理地址的机制、读和写、共享与保护等功能。
3. **文件系统的接口**：为方便用户使用文件系统，文件系统通常向用户提供使用的接口。

**文件系统模型**

用户（程序）→文件系统接口→对对象操作和管理的软件集合→对象及其属性

## 7.2文件的逻辑结构

**逻辑结构**：是从用户的观点出发所看到的文件组织形式，是用户可以直接操作的数据及其结构。

**物理结构**：又称为文件的存储结构，是指文件在外存上的存储组织形式，与存储介质的存储性能有关。

### 7.2.1文件逻辑结构的类型

文件的**逻辑结构**通常分为两种形式：	记录式文件和流式文件。

**记录式文件又称有结构文件**，是数据记录的集合，是一种有结构的文件组织。这是逻辑结构研究的重点。

**流式文件又称无结构文件**，是由一组相关信息组合成的有序字符流。其基本单位是字节它这种文件的长度直接按字节计算。

## 7.3目录管理

为了实现文件信息的“**按名存取**”，一般用**文件目录**的方法来管理文件，每个文件有一个目录项（FCB）

**FCB**：文件控制块操作系统为管理文件而设置的数据结构，存放了为管理文件所需的所有有关信息。

**文件目录**：文件控制块的有序集合称为文件目录。一个文件目录也被看做事一个文件，称为目录文件

​	目录管理实现 主要工作：

1. 实现“按名存取”
2. 提高对目录的检索速度
3. 文件共享

索引结点：

1. 索引结点的引入：提高速度

   查找目录的过程中，是将用户给定的文件名与目录项中的文件名逐一比较。

   UNIX系统把文件描述信息单独形成一个称为索引结点的数据结构。使得同样大小的盘块目录项数增加。在查找时启动磁盘次数减少。

### 7.3.2目录结构

1. 单级目录结构

2. 二级目录结构

   1. 二级文件目录的形成
      - 主目录：多个用户的信息
      - 用户文件目录：每一个用户的信息

3. 多级目录结构

   1. 路径名

      在树形目录结构中，从根目录到任何数据文件，都只有一条惟一的通路。系统中的每一个文件都有惟一的路径名。**从树根开始直到树叶(数据文件)为止的、包括各中间结点(目录)名为全路径名**。

   2. 当前目录

      全路径名太麻烦。基于这一点，**可为每个进程设置一个“当前目录”**，又称为“工作目录”。进程对各文件的访问都相对于“当前目录”而进行。

   把从当前目录开始直到数据文件为止所构成的路径名，称为**相对路径名(relative path name)**；而把从树根开始的路径名称为**绝对路径名(absolute path name)或全路径名**。

## 7.4/5文件共享和文件保护

### 利用基本文件目录实现文件共享

硬链接：直接连接

利用符号链实现文件共享——软连接

### 文件保护技术

**访问控制**：

​	检查用户对文件的**访问权限**与本次访问是否一致

- 访问控制矩阵
  - 列出全部用户和文件之间的访问权限
- 简化访问表（存取控制表）
  - 在文件中针对文件主，同组用户和其它用户给出访问权限

# 8磁盘存储器的管理

## 8.1外存的组织方式

### 8.1.1连续组织方式

**连续分配的主要优点**：

1. 顺序访问容易
2. 顺序访问速度快

**连续分配的主要缺点**：

1. 要求有连续的存储空间
2. 必须事先知道文件的长度

### 8.1.2链接组织方式

1. 隐式链接：

   块内部存有下一个块的地址

2. 显示链接：

   使用FAT表链接

### 8.1.3索引分配

1. 单级索引分配

   连接分配方式虽然解决了连续分配方式所存在的问题，但又出现了另外两个问题，即：

   1. 不能支持高效的直接存取。要对一个较大的文件进行直接存取，须首先在FAT中顺序地查找许多盘块号。
   2. FAT需占用较大的内存空间。

2. 多级索引分配

3. 增量式索引组织方式

## 8.2文件存储器空间管理

文件存储于文件卷中，文件卷可以是一个物理盘，也可以是一个物理盘的一部分，一个支持超大型文件的文件卷也可以由多个物理盘组成。

### 8.2.1空闲表法和空闲链表法

### 8.2.2位示图法

1. 位示图

2. 盘块的分配

   1. 顺序扫描位示图，从中找出一个或一组其值为“0”的二进制（“0”表示空闲时）

   2. 将所找到的一个或一组二进制位， 转换成与之相应的盘块号。假定找到的其值为“0”的二进制位，位于位示的第i行、第j列，则其相应的盘块号应按下式计算：
      $$
      b=n(i-1)+j
      $$
      n代表每行的位数

   3. 修改位示图，令
      $$
      map[i,j]=1
      $$

3. 盘块的回收

   1. 将回收的盘块号转换成位示图中的行号和列号。

      转化公式为：
      $$
      i=(b-1)DIV n+1
      $$

      $$
      j=(b-1)MODn+1
      $$

      修改位示图
      $$
      map[i,j]=0
      $$
      

## 8.3提高磁盘I/O速度的途径

### 8.3.1磁盘高速缓存

是指利用内存中的存储空间，来暂存从磁盘中读出的一系列盘块中的信息。即在内存中，为磁盘盘块设置一个缓冲区，在缓冲区中保存了某些盘块的副本。

1. 数据交付方式
   1. 数据支付：直接从高速缓存中的数据传送到请求者进程的内存工作区中。
   2. 指针交付：只将指向高速缓存中某区域的指针，交付给请求者进程。这种方式所传送的数据量少，因而节省时间。

### 8.3.2提高磁盘I/O速度的其他方法

1. 提前读
2. 延迟写
3. 优化物理块分布
4. 虚拟盘

### 8.3.3廉价磁盘冗余阵列

1. 并行交叉存取
2. RAID的分级
   1. RAID	0级：提供并行交叉存取。
   2. RAID    1级：具有镜像磁盘功能。
   3. RAID    3级：提供并行交叉存取的校验功能。
   4. RAID    5级。
   5. RAID    6级和RAID    7级。
3. RAID的优点
   1. 可靠性高
   2. 磁盘I/O速度高
   3. 性能/价格比高