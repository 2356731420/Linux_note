# 操作系统

# 1.操作系统引论

## 1.1操作系统的目的和作用

### 1.1.1操作系统的目标

通常在计算机硬件配置的OS(操作系统),其目标有以下几点:

1. 方便性——便于使用
2. 有效性——效率高
3. 可扩充性——方便增加模块
4. 开放性——兼容性

### 1.1.2操作系统的作用

1. OS作为用户与计算机硬件系统之间的接口

   OS处于用户与计算机硬件系统之间，用户通过OS来使用计算机系统

## 1.2操作系统的发展过程

### 1.2.1无操作系统的计算机系统

1. 穿孔

2. 纸带

3. 卡片

4. 纸带输入机

5. 卡片输入机

   缺点：

   1. 用户独占全机
   2. CPU等待人工操作

### 1.2.2单道批处理系统

### 1.2.3多道批处理系统

### 1.2.4分时系统

1. 分时系统的产生

   推动分时系统产生和发展的主要动力，则是用户的需求：<u>**人机交互，共享主机**</u>

2. 分时系统实现中的关键问题

   **<u>最关键的问题是如何使用户能与自己的作业进行交互</u>**

   1. 及时接收
   2. 及时处理

3. 分时系统的特征

   1. **<u>多路性</u>**
   2. **<u>独立性</u>**
   3. **<u>及时性</u>**
   4. **<u>交互性</u>**

### 1.2.5实时系统

**实时系统**是指系统能及时（或即时）响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地运行

<u>**应用需求 1、实时控制 2、实时信息处理**</u>

**<u>硬实时任务：工业控制系统，嵌入式系统</u>**

**<u>软实时任务：信息查询系统，多媒体系统</u>**

1. 分时系统侧重于：多个用户终端的互不干扰，人机交互。
2. 实时系统侧重于：多路控制现场设备、数据互不干扰，特定程序间的数据信息交互。

## 1.3操作系统的基本特性

*并发性*：**宏观同时，微观交错**

*共享性*：**并发执行，共用资源**

*虚拟性*：**物理设备**<u>**(单个)**</u> 	**<u>复用</u>**	—>	**逻辑设备**<u>**(多个)**</u> 	**<u>时分复用	空分复用</u>**

*异步性*：**多进程交替，执行断续性**

注意：*并行与并发的区别*

**<u>并发</u>和<u>共享</u>是操作系统的两个最基本的特征，它们互为存在的条件。**

## 1.4操作系统的主要功能

操作系统是一组控制和管理计算机硬件和软件资源、合理地对各类作业进行调度，以及方便用户的程序的集合

## 1.5操作系统的结构设计

### 1.5.1传统的操作系统结构

四代变革：

1. 传统结构操作系统
   1. 无结构OS
   2. 模块式OS
   3. 层次式结构OS
2. 现代结构操作系统
   1. 客户/服务器模式
   2. 面向对象的程序设计
   3. 微内核结构OS

# 2.进程管理

## 2.1进程的基本概念

### 2.1.1前趋图

广度搜索

### 2.1.2程序并发执行时的特征：

1. 间断性
2. 失去封闭性
3. 不可再现性

### 2.1.3程序顺序执行时的特征：

1. 顺序性
2. 封闭性
3. 可再现性

## 2.2进程控制

### 2.2.1进程的定义和特征

1. **<u>进程的定义</u>**：

   1. 进程是程序的一次<u>**执行**</u>，是进程实体的**<u>运行过程</u>**
   2. 进程是可并发执行的<u>**程序**</u>在一个<u>**数据集合**</u>上的运行过程。它是系统进行资源分配和调度的一个独立单位.

   进程实体由程序段、数据段、进程控制块(<u>**PCB**</u>)构成

   注：进程与程序的主要区别

   <u>程序</u>是指令的集合，本身没有任何运行的含义，是一个静态概念；而<u>**进程**</u>是程序在处理机上的一次执行过程，是一个动态概念。

### 2.2.2进程基本状态及其转换

**进程的状态反映进程执行过程的变化**

1. **进程的三种基本状态**：

   **运行态**：**进程占有CPU，并在CPU上运行**

   **就绪态**：指进程已获得了除处理机之外的所有所需的资源，已经具备运行条件，但由于无CPU暂时不能运行的状态。（当调度给其CPU时，立即可以运行）

   **阻塞态**：**等待态、封锁态、睡眠态**。指进程因等待某种事件的发生而暂时不能运行的状态（即使CPU空闲，该进程也不可能运行）

2. 三种基本状态的转换

   进程因某事件从运行到阻塞状态

   某事件被解除从阻塞变成就绪

   时间片用完从运行到就绪

   进程调度程序把处理机分配给进程从就绪到运行

### 2.2.4进程管理中的数据结构PCB

**PCB是操作系统中最重要的数据结构，是进程存在的唯一标志；是独立运行的基本单位，是资源分配的基本单位。**

进程控制块的信息和作用：

​	<u>**进程标识信息**</u>，是进程的唯一标识

​	<u>**处理机状态**</u>，即是现场信息保存的地方，从而能实现间断性运行方式：
​	<u>**进程调度信息**</u>：提供进程调度所需要的信息；
​	<u>**进程控制信息**</u>：提供进程管理所需要的信息，所有资源的列表；实现与其他进程的同步与通信

PCB的组织方式

1. 链接方式
2. 索引方式

## 2.3进程同步

### 2.3.1操作系统内核

为了确保系统的安全性，常将处理机的执行状态分为<u>**系统态**</u>和<u>**用户态**</u>。

进程控制由操作系统内核实现，运行于系统态。

<u>**OS内核**</u>是计算机硬件的第一次扩充，由一些与硬件紧密相关的模块和运行频率较高的模块构成，例如中断，各种管理，进程调度的，驱动程序等等。内核常驻内存，受特殊保护，为了效率高和安全性。

**<u>原语</u>**是由若干条指令组成的，用于完成特定功能的一个特殊过程。它与一般过程的区别在于：它们是**<u>原子操作</u>**，不能被打断。

### 2.3.2进程的创建

1. 申请空白PCB
2. 为新进程分配资源
3. 初始化进程控制块
   1. 初始化表示信息
   2. 初始化处理机状态信息，pc指针等现场信息
   3. 初始化处理机控制信息：状态，优先级
4. 将新进程插入就绪队列，如果进程就绪队列能够接纳新进程， 便将新进程插入就绪队列

## 2.4经典进程的同步问题

<u>**进程同步**</u>： 指对多个相关进程在执行次序上的协调。

<u>**进程同步的主要任务**</u>：  使并发执行的诸进程间能有效地共享资源和相互合作，从而使程序的执行具有可再现性。

### 2.4.1进程同步的基本概念

1. 两种形式的制约关系：

   1. *资源共享关系（间接互相制约）*<u>**互斥解决**</u>
   2. 相互合作关系（直接相互制约）<u>**同步解决**</u>

2. 临界资源

   一段时间内只允许一个进程访问的资源；临界资源要求互斥的被访问。

3. 临界区的定义

   各进程中访问临界资源的程序代码称为临界区。

4. 同步机制遵循的规则

   1. 空闲让进
   2. 忙则等待
   3. 有限等待
   4. 让权等待

### 2.4.2硬件同步机制

硬件的理解，解决方式：

1. 关中断：

   缺点：

   1. 滥用关中断，会有严重后果
   2. 关中断时间过长，效率会低
   3. 不适用多cpu系统

   方法2/3都相当于加锁方式原理：

   1. 如果锁lock=true，就while循环等待
   2. 一旦false了，就马上出循环，lock=true，并使用资源；
   3. 使用完资源了，lock=false

### 2.4.3信号量机制

通过两个标准的原子操作：<u>**wait(S)**</u>和<u>**signal(S)**</u>来访问。这两个操作一般被分别称为<u>**P、V操作**</u>。

1. 整形信号量

   ```c++
   wait(S){  while （S≤0）;
             S=S-1;   }
   ```

   P操作：实现资源分配

   ```c++
   signal(S){S=S+1;}
   ```

   V操作：实现资源回收

2. 记录型信号量

   整型变量value：代表资源数目

   进程链表指针L：链接等待该资源的进程

   ```c++
   typedef struct {
          int  value;
           Block_List  * list;      
            } semaphore
   wait(semaphore  *S)
   {
         S->value--;
         if (S->value＜0 )
              block(S->list)
   }
   signal(semaphore  *S)
         S->value++;
         if (S->value＜=0 )
              wakeup(S->list)
   }
   ```

   1. <u>**S.value的初值表示系统中某类资源的数目**</u>， 因而又称为资源信号量，每次wait操作意味着进程请求一个单位的该类资源，S.value:=S.value-1 
   2. 当S.value＜0时，进程自阻塞，<u>**S.value的绝对值表示在该信号量链表中已阻塞进程的数目**</u>。
   3. 该机制遵循了“让权等待”准则。
   4. 如果<u>**S.value的初值为1**</u>，表示只允许一个进程访问临界资源，此时的信号量<u>**转化为互斥信号量**</u>。 

## 2.5进程通信

进程通信是指进程之间的信息交换。根据信息量的大小，可把进程之间的通信分成<u>**低级通信**</u>和<u>**高级通信**</u>。

### 2.5.1进程通信的类型

1. 共享存储器系统：

   1. 基于共享数据结构的通信方式：信号量
   2. 基于共享存储区的通信方式

2. 管道通信：

   利用一个打开的pipe共享文件连接两个相互通信的进程。有效的传送大量的数据。

3. 消息传递系统：

   1. 直接通信方式：消息传递原语
   2. 间接通信方式：邮箱通信

## 2.6线程

### 2.6.1线程的引入

进程的创建和切换开销比较大，为了减少进程切换和创建的开销，提高执行效率和节省资源，以及为了方便进程间共享数据和交换数据，引入“线程”。

### 2.6.2线程的实现

两种：

1. 内核级线程
   1. CPU是内核直接分配给线程的
2. 用户级线程
   1. CPU的是分配给进程的，进程自己的分配给线程

特点：

1. 内核不了解用户线程的存在；
2. 用户线程切换不需要内核特权
3. 调度由应用软件内部进行，通常采用非抢先式和更简单的规则，也无需用户态/核心态切换，所以速度特别快。

# 3.处理机调度与死锁

## 3.1处理机调度的层次

### 3.1.1处理机调度的层次

<u>**高级调度**</u>：选取输入井中的作业（仅限于批作业调度)，生成根进程，开始执行作业步.目的是控制使用系统资源的进程数。

<u>**中级调度**</u>：选取进程占用内存或有资格占用内存，又称进程滚入滚出。

<u>**低级调度**</u>：选取进程占用处理机,又称进程调度。

<u>进程调度</u>：是指按一定的调度算法从就绪队列中选中一个进程，把CPU的使用权交给被选中的进程，从而控制协调进程对CPU的竞争。

### 3.1.2调度算法的目标

**性能衡量的指标**：

​	**周转时间**：一个作业从提交到返回所需的时间。

​	**<u>平均周转时间</u>**：
$$
T = \frac 1 n [ \sum_ {i=1} ^n T_i ]
$$
**面向用户的准则**：周转时间短；响应时间快；截止时间的保证；优先权准则

**面向系统的准则**：系统吞吐量高；处理机利用率好；各类资源的平衡利用。

## 3.2作业与作业调度

### 3.2.3作业调度算法:

1. 先进先出（FIFO）算法
2. 最短CPU运行期优先调度算法
3. 最高响应比优先法
4. 优先级法

**最高响应比优先法** 
是前两种算法的综合平衡，既要考虑到服务时间也要考虑到等待时间，响应比作为优先权：
$$
优先权=\frac{等待时间+要求服务}{要求服务时间}=\frac{响应时间}{要求服务时间}
$$


## 3.3调度算法

### 3.3.2基于时间片的轮转调度算法

1. 时间片轮转法

   1. 基本原理：把CPU按时间片分配给进程，<u>**进程按时间片大小轮流执行**</u>。
   2. 进程切换时机
   3. 时间片的大小选择，从几ms到几百ms

2. 多队列反馈调度算法

   1. 就绪队列分为N级，每个就绪队列分配给不同的时间片
   2. 队列级别越低，时间越长，级别越高，时间片越小
   3. 最后一级采用时间片轮转，其他队列采用先进先出

   调度处理：

   1. 系统从第一级调度，第一级为空时，系统转向第二个队列...
   2. 当进程第一次就绪时，进入第一级队列
   3. 当运行进程用完一个时间片，放弃CPU时，进入下一级队列
   4. 因为等待事件放弃CPU时，进入原来的(或更高的)就绪队列

## ~~3.4实时调度~~

## 3.5产生死锁的原因和必要条件

死锁（Deadlock）定义：是指系统中多个进程无休止地等待永远不会发生的条件，若无外力作用，这些进程都将无法向前推进。

产生死锁的原因是：系统资源不足；并发进程执行时推进顺序不当。

产生死锁几个必要条件

1. 互斥条件
2. 请求和保持条件（部分分配条件）
3. 不可抢占条件
4. 循环等待条件

**解决死锁的基本方法**

1. <u>**死锁预防**</u>：事先就破坏其中一个必要条件
2. <u>**死锁避免**</u>：分配资源的时候，检测是不是安全，如果不安全就不分配。
3. <u>**死锁检测、解除死锁（死锁的检测和恢复）**</u>：事先不管，定时检测是否有死锁，有则解除死锁。

## 3.6预防死锁的方法

1. 破坏必要条件中的部分分配条件，对进程申请的资源一次性全部分配
2. 破坏必要条件中的不可抢占条件，进程申请新资源的请求不能满足时，必须释放已占有的资源
3. 破坏必要条件中的循环等待条件，按一定的资源序列号升序地分配资源

## 3.7死锁的避免

**实质：在资源的动态分配过程中**，使系统不进入<u>**不安全状态**</u>。 在避免死锁的方法中，允许进程动态地申请资源，但系统在<u>**进行资源分配之前**</u>，应先计算此次资源分配的<u>**安全性**</u>。若此次分配不会导致系统进入不安全状态，则将资源分配给进程； 否则，令进程等待。

避免死锁算法最有代表性的是Dijkstra提出的<u>**银行家算法**</u>。

​	思想：

1. 假设，分配给你资源后（值修改）；

2. 判断是否为安全状态，是则分配，不是则不分配。

   **怎样判断是不是安全状态（安全算法）：看能不能找到一个安全序列**

### 系统的安全状态

系统状态：

​	<u>**安全状态**</u>：指系统能按照某种顺序如
$$
<P1,P2,…,Pn>
$$
 (称为这个序列为安全序列)，为每个进程分配所需的资源，直至最大需求，使得每个进程都能顺利完成。

​	<u>**非安全状态**</u>：即在某个时刻系统中不存在一个安全序列，则称系统处于不安全状态或非安全状态。

**<u>因此，避免死锁的实质是如何使系统不进入不安全状态</u>**

## 3.8死锁的检测与解除

### 3.8.1死锁的检测：判定系统是否发生了死锁

# 4.存储器管理

**主要任务**：

1. 为多道程序的运行提供良好的环境（安全可靠）
2. 提高存储器的利用率
3. 逻辑上扩充内存

**主要功能：**

1. 内存分配
2. 地执映射
3. 内存保护
4. 内存扩充

## 4.1存储器的层次结构

### 4.1.1多级存储器结构

1. 寄存器
2. 高速缓存
3. 主存
4. 磁盘缓存
5. 磁盘
6. 磁带、光盘、移动存储等

速度由快到慢，容量从小到大，价格从高到低

## 4.2程序的装入和链接 

程序	**编译**	到目标模块	**链接**	到装入模块	**装入**	内存

### 地址转换—基本概念：

**逻辑地址（相对地址，虚地址）** ：用户的程序经过汇编或编译后形成目标代码，目标代码通常采用相对地址的形

式，其首地址为0，其余指令中的地址都相对于首地址而编址。**由编译程序生成，不能用逻辑地址在内存中读取信息**。

**物理地址（绝对地址，实地址）**：内存中存储单元的地址，可直接寻址。

**地址转换**：为了保证CPU执行指令时可正确访问存储单元，需将用户程序中的逻辑地址转换为运行时由机器直接寻址的物理地址，这一过程称为地址映射。

### 地址映射

**静态地址转换**
当用户程序被装入内存时，一次性实现逻辑地址到物理地址的转换，以后不再转换一般在装入内存时由软件完成

**动态地址转换**
在程序运行过程中要访问数据时再进行地址变换(一般此工作由硬件地址映射机制来完成)硬件上需要寄存器的支持

### 4.2.1程序的装入

1. 绝对装入方式：

   <u>**适用于单道环境，例如单片机**</u>

2. 可<u>**重定位**</u>装入方式

   <u>**静态地址映射**</u>

3. 动态运行时装入方式

   <u>**动态地址映射**</u>

### 4.2.2程序的链接

程序链接：将几个目标模块装配成一个装入模块

1. **静态链接方式**

2. **装入时动态链接**

   装入时动态链接的<u>**优点**</u>：

   1. **<u>便于修改和更新</u>**
   2. **<u>便于实现对目标模块的共享</u>**

   缺点：所有的模块都装入了

3. **运行时动态链接**

   许多情况下，程序在运行时，每次要运行的模块可能是不相同的 ，**目前流行的是动态链接，是运行时再把需**
   **要的模块装入进去**。

## 4.3连续分配方式 

连续空间分配：进程的空间是连续的。

### 4.3.1单一连续分配：

1. 只能用于单用户、单任务操作系统

2. 内存分为系统区和用户区两部分

   **特点：易理解、效率高、空间利用率低**

### 4.3.2固定分区分配：

特点：任一时刻内存可有多道内存，每个内存连续存放于内存.

**基本思想**：

**系统把内存用户区划分为若干块，每块称为分区。**

**分区大小可相同也可不同。**

**一个进程占据一个分区。**

**分区大小固定不变的称为固定分区**

### 4.3.3-4.3.4动态分区分配和分配算法

**特点：多道、连续、但不固定划分内存**

1. 管理方法：

   系统设置一个空闲块队列，初始状态时队列中只有一个连续的空闲块。作业到达后，以某种策略分配空间。作业撤离时，将释放的空间加入空闲队列

**分配方法**：

按照一定的分配策略，找到合适的空闲块后，从其中将作业大小的空间分给作业，而剩余部分挂入空闲队列。

分配策略包括：

**首次适应法**：从F(可用块集合)中最先找到的空闲块

**循环首次适应算法**：从上次的位置的下一个位置开始找，而不是又从头找

**最佳适应法**：从F中找到的满足条件的最小空闲块。

**最大满足法**:从F中找到的满足条件的最大空闲块。

### 4.3.6动态可重定位分区分配

1. **紧凑：通过移动作业位置可以将零散的空闲块连接成大块。要求作业动态可浮动。**

## 4.4对换

1. 对换的引入：**解决内存扩充问题**

   **<u>对换</u>**：把内存中暂时不能运行的进程或者暂时不用的程序和数据，调出到外存上。

   **<u>对换是提高内存利用率的有效措施</u>**

   1. 整体对换—>进程对换
   2. 部分对换（页面对换，分段对换）

## 4.5分页存储管理方式

<u>**离散分区分配**</u>：将一个进程（或作业）直接分散地分配到许多不必相邻接的分区中，而不需要进行“紧凑”

离散分区分配方式，包括：

1. 分页存储管理
2. 分段存储管理
3. 段页式存储管理

### 4.5.1分页存储管理的基本方法

1.**基本思想（工作原理）	空间安排**：

进程分成页面，内存也划分成页面，以**页为单位**进行分配，并按**进程的页数**多少来分配，将进程页面不连续地分

布到内存页面

2.**地址结构**

页号P	位移量W
$$
P=INT[\frac AL]
$$

$$
W = [A]\ MOD\ L
$$
3.页表

**页表：存放逻辑页与物理页帧的对应关系**。

### 4.5.2地址变换结构

$$
分页逻辑地址=P(页号)·W(页内位移)
$$

$$
分页物理地址=f(页帧号)·W(页内位移)
$$

**给一个逻辑地址、页面大小和页表，会计算该逻辑地址对应的物理地址。**

怎么计算：

1.计算逻辑页号和页内偏移

2.查找页表，找出对应的物理块号

3.计算出物理地址：物理块号*页面大小+页内偏移

### 4.5.3两级和多级页表

页表的问题：

1. 逻辑地址空间越来越大(2^32^~2^64^)
2. 页表也就变得非常大，占用内存空间越来越大

## 4.6分段存储管理方式 

**段式管理的空间划分**：按作业的自然段将其逻辑空间分成若干段，作业以段为单位分配内存。

### 4.6.2分段系统的基本原理

1. 分段

   分段管理中的地址结构：

   段号（31-16）+段内地址（15-0）

2. 段表

### 4.6.3信息共享

可重用代码（纯代码）

**段页式管理**：结合段式和页式两种方法，将作业分成若干段，每段用页式管理实现内存分配。

# 5.虚拟存储器